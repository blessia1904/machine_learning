library(pls)
library(ISLR2)
library(caret)
View(Boston)
set.seed(14)
# Split data into training (80%) and test (20%) sets
trainIndex <- createDataPartition(Boston$medv, p = 0.8, list = FALSE, times = 1)
train <- Boston[trainIndex, ]
test <- Boston[-trainIndex, ]
# Find the num of components
model_pcr <- pcr(medv ~ ., data = train, center = TRUE, scale = TRUE, validation = "CV")
summary(model_pcr)
RMSEP(model_pcr)$val[1,,]
myrmse <- RMSEP(model_pcr)$val[1,,]
which.min(myrmse)
# RMSE in the testing sample =
pcr_pred <- predict(model_pcr, test, ncomp = 12)
rmse(pcr_pred, test$medv)
library(Metrics)
install.packages("Metrics")
library(Metrics)
rmse(pcr_pred, test$medv)
model_pls <- plsr(medv ~ ., data = train, center = TRUE, scale = TRUE, validation="CV")
summary(model_pls)
validationplot(model_pls, val.type = "RMSEP")
myrmse <- RMSEP(model_pls)$val[1,,]
RMSEP(model_pls)$val[1,,]
which.min(myrmse) # 14 components
# RMSE in the testing sample = 2.001386
pls_pred <- predict(model_pls, test, ncomp = 9)
rmse(pls_pred, test$medv)
model_ridge <- lm.ridge(medv ~ ., data = train, lambda = seq(0, 10, 0.1), cv = TRUE)
summary(model_ridge)
ridge_pred <- predict(model_ridge, newdata = test)
test
library(glmnet)
dim(Boston)
dim(train)
X_train <- model.matrix(medv ~ ., data = train)[,-1]
X_train
y_train <- train$medv
X_test <- model.matrix(medv ~ ., data = test)[,-1]
y_test <- test$medv
cv_model <- cv.glmnet(x = X_train, y = y_train, alpha = 0, nfolds = 10)
summary(cv_model)
model_ridge <- cv.glmnet(x = X_train, y = y_train, alpha = 0, nfolds = 10)
ridge_pred <- predict(model_ridge, newx = X_test, s = "lambda.min")
ridge_pred
#summary(model_ridge)
model_ridge$lambda.min
ridge_pred <- predict(model_ridge, newx = X_test, s = "lambda.min")
rmse(ridge_pred, y_test)
# Fit a lasso regression model
model_lasso <- cv.glmnet(x = X_train, y = y_train, alpha = 1, nfolds = 10)
# min λ chosen by CV
model_lasso$lambda.min
# RMSE in the testing sample =
lasso_pred <- predict(cv_model, newx = X_test, s = "lambda.min")
rmse(lasso_pred, y_test)
# number of non-zero coefficient estimates
coef(cv_model, s = "lambda.min")
# Fit a lasso regression model
model_lasso <- cv.glmnet(x = X_train, y = y_train, alpha = 1, nfolds = 10)
# min λ chosen by CV
model_lasso$lambda.min
# RMSE in the testing sample = 4.210299
lasso_pred <- predict(model_lasso, newx = X_test, s = "lambda.min")
rmse(lasso_pred, y_test)
Boston = Boston
View(Boston)
mean(Boston$medv)
mean(Boston$medv)
